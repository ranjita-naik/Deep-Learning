{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import os\n",
    "import six\n",
    "import time\n",
    "import pylab\n",
    "import pickle, gzip\n",
    "import numpy as np\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import serializers\n",
    "from chainer import optimizers\n",
    "from matplotlib import gridspec\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "%matplotlib inline\n",
    "    \n",
    "N = 60000\n",
    "N_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_data(path):\n",
    "    \n",
    "    mnist_pickle = open('data/mnist.pkl', 'rb')\n",
    "    u = pickle._Unpickler( mnist_pickle )\n",
    "    u.encoding = 'latin1'\n",
    "    mnist =  u.load()\n",
    "    \n",
    "    num_train = 60000\n",
    "    num_test = 10000\n",
    "\n",
    "    mnist['data'] = mnist['data'].astype(np.float32)\n",
    "    mnist['data'] /= 255\n",
    "    mnist['data'] = mnist['data'].reshape(mnist['data'].shape[0], 1, 28, 28)\n",
    "    mnist['target'] = mnist['target'].astype(np.int32)\n",
    "\n",
    "    input_train, input_test = np.split(mnist['data'],   [num_train])\n",
    "    target_train, target_test = np.split(mnist['target'], [num_train])\n",
    "    return input_train, target_train, input_test, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__(\n",
    "            c1=L.Convolution2D(1, 9, 5),\n",
    "            f3=L.Linear(5184, 10),\n",
    "        )\n",
    "\n",
    "        self.outputs = [0] * 4\n",
    "        self.num_layers = 4\n",
    "\n",
    "    def __call__(self, x):\n",
    "        output = x\n",
    "        output = self.c1(output)\n",
    "        output = F.relu(output)\n",
    "        output = self.f3(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_weights(self, layer):\n",
    "        if layer == 1:\n",
    "            return self.c1.W.data\n",
    "        elif layer == 3:\n",
    "            return self.f3.W.data\n",
    "        else:\n",
    "            raise ValueError(\"Layer does not have weights: {}\".format(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, batchsize = 100, num_epochs = 20):    \n",
    "    optimizer = optimizers.Adam()\n",
    "    optimizer.setup(model)\n",
    "\n",
    "    for epoch in six.moves.range(1, num_epochs + 1):\n",
    "        print('epoch', epoch)\n",
    "\n",
    "        # training\n",
    "        perm = np.random.permutation(N)\n",
    "        sum_accuracy = 0\n",
    "        sum_loss = 0\n",
    "\n",
    "        for i in six.moves.range(0, N, batchsize):\n",
    "            x = chainer.Variable(np.asarray(images_train[perm[i:i + batchsize]]))\n",
    "            t = chainer.Variable(np.asarray(labels_train[perm[i:i + batchsize]]))\n",
    "\n",
    "            optimizer.update(model, x, t)\n",
    "\n",
    "            sum_loss += float(model.loss.data) * len(t.data)\n",
    "            sum_accuracy += float(model.accuracy.data) * len(t.data)\n",
    "\n",
    "        print('train mean loss={}, accuracy={}'.format(\n",
    "                sum_loss / N, sum_accuracy / N))\n",
    "\n",
    "        # evaluation\n",
    "        sum_accuracy = 0\n",
    "        sum_loss = 0\n",
    "        for i in six.moves.range(0, N_test, batchsize):\n",
    "            x = chainer.Variable(np.asarray(images_test[i:i + batchsize]))\n",
    "            t = chainer.Variable(np.asarray(labels_test[i:i + batchsize]))\n",
    "\n",
    "            loss = model(x, t)\n",
    "            sum_loss += float(loss.data) * len(t.data)\n",
    "            sum_accuracy += float(model.accuracy.data) * len(t.data)\n",
    "\n",
    "        print('test  mean loss={}, accuracy={}'.format(sum_loss / N_test, sum_accuracy / N_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "train mean loss=0.250836377479136, accuracy=0.929533335318168\n",
      "test  mean loss=0.10808072537649423, accuracy=0.9674000072479249\n",
      "epoch 2\n",
      "train mean loss=0.09082891652050118, accuracy=0.973600009183089\n",
      "test  mean loss=0.07338494185125455, accuracy=0.9787000077962875\n",
      "epoch 3\n",
      "train mean loss=0.06521509442711249, accuracy=0.9811166777213415\n",
      "test  mean loss=0.06055964846280403, accuracy=0.9820000070333481\n",
      "epoch 4\n",
      "train mean loss=0.05253319886745885, accuracy=0.9838666767875354\n",
      "test  mean loss=0.058497425749956165, accuracy=0.9819000089168548\n",
      "epoch 5\n",
      "train mean loss=0.043599698273465035, accuracy=0.9865333426992099\n",
      "test  mean loss=0.052942996900237634, accuracy=0.9839000076055526\n"
     ]
    }
   ],
   "source": [
    "images_train, labels_train, images_test, labels_test = load_mnist_data('data/mnist.pkl')\n",
    "N_test = labels_test.size\n",
    "simple_model = L.Classifier(SimpleCNN())\n",
    "train_model(simple_model, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PoolingCNN(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super(PoolingCNN, self).__init__(\n",
    "            c1=L.Convolution2D(1, 9, 5),\n",
    "            f3=L.Linear(1296, 10),\n",
    "        )\n",
    "\n",
    "        self.num_layers = 4\n",
    "        self.outputs = [0] * self.num_layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        output = x\n",
    "        output = self.c1(output)\n",
    "        output = F.relu(F.max_pooling_2d(output, 2, stride=2))\n",
    "        output = self.f3(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_weights(self, layer):\n",
    "        if layer == 1:\n",
    "            return self.c1.W.data\n",
    "        elif layer == 3:\n",
    "            return self.f3.W.data\n",
    "        else:\n",
    "            raise ValueError(\"Layer does not have weights: {}\".format(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "train mean loss=0.3294397140542666, accuracy=0.9100166686251759\n",
      "test  mean loss=0.13597849015612154, accuracy=0.9618000036478043\n",
      "epoch 2\n",
      "train mean loss=0.1150416758004576, accuracy=0.9671833403905232\n",
      "test  mean loss=0.08257284199818969, accuracy=0.9761000049114227\n",
      "epoch 3\n",
      "train mean loss=0.0825290200393647, accuracy=0.9763500101367633\n",
      "test  mean loss=0.06976450882502831, accuracy=0.9790000063180924\n",
      "epoch 4\n",
      "train mean loss=0.06739653394557536, accuracy=0.9804500110944112\n",
      "test  mean loss=0.059802431911812164, accuracy=0.9810000079870224\n",
      "epoch 5\n"
     ]
    }
   ],
   "source": [
    "pooling_model = L.Classifier(PoolingCNN())\n",
    "train_model(pooling_model, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
